<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title> MicroISP Project </title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,700italic,400italic" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <script src="js/modernizr.js"></script>
    <meta name="viewport" content="width=device-width">

    <script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	
	  ga('create', 'UA-105303874-1', 'auto');
	  ga('send', 'pageview');
    </script>
</head>

<!--
<button id="demo-button" class="online-demo" onclick="open_demo();"><img src="assets/img/demo_button2.png"></button> 

<div id="demos" style="display:none">
	<a href="#" style="position: fixed; right: 2.2vmax; top: 6.3vw; color: white; z-index:9999; text-decoration: none; font-size: 1.2vmax;" onclick="close_demo()"> &#10006; </a>
	<iframe class="demo" src="http://quality-gpu.eastus.cloudapp.azure.com:8080" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" >
	<!--<iframe class="demo" src="http://127.0.0.1:5000/" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" >
	</iframe>
</div>
-->

<body data-spy="scroll" data-offset="0" data-target="#navbar-main">

<!-- ==== MENU ==== -->

<nav>
	<ul class="left_bar">
		<a href="index.html"> <li2> DPED </li2></a>
		<a href="wespe.html"> <li2> WESPE </li2></a>
		<a href="pynet.html"> <li2> PyNET </li2></a>
		<a href="pynet-bokeh.html"> <li2> Bokeh </li2></a>
		<a href="microisp.html"> <li2 style="background-color: rgba(233,79,112, 0.85);"> MicroISP </li2></a>
		<a href="camsdd.html"> <li2> CamSDD </li2></a>
		<a href="midd.html"> <li2> MIDD </li2></a>
	</ul>
	<ul class="middle_bar">
		<a href="#title"> <li> PAPER </li></a>
		<a href="#demo"> <li> DEMO </li></a>
		<a href="#dataset"> <li> DATASET </li></a>
		<a href="#algo"> <li> ALGO </li></a>
		<a href="#code"> <li> CODE </li></a>
	</ul>
	<ul class="right_bar">
		<a target="_blank" href="http://www.vision.ee.ethz.ch/en/" > <li> <img src="assets/img/eth_logo.png"> </li></a>
		<a href="#about"> <li> ABOUT </li></a>
	</ul>
</nav>

<div id="title">
<h1 class="title"> MicroISP: Processing 32MP Photos on Mobile Devices with Deep Learning </h1>

<table class="authors-pynet">
<tr>
	<td><a target="_blank" class = "link-invisible" href="https://ch.linkedin.com/in/andrey-ignatov">Andrey Ignatov</a></td>
	<td><a target="_blank" class = "link-invisible" href="https://ch.linkedin.com/in/nastyasycheva">Anastasia Sycheva</a></td>
	<td><a target="_blank" class = "link-invisible" href="https://cvlai.net/">Radu Timofte</a></td>
	<td><a target="_blank" class = "link-invisible" href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a></td>
</tr>
<tr class="emails">
	<td>ihnatova@ethz.ch</td>
	<td>nastya.sycheva89@gmail.com</td>
	<td>radu.timofte@uni-wuerzburg.de</td>
	<td>vangool@vision.ee.ethz.ch</td>
</tr>
</td>
</table>

<h1 class="institute" style="font-size: 1.1vw;"> And MediaTek Inc.: Yu Tseng, Yu-Syuan Xu, Po-Hsiang Yu, Cheng-Ming Chiang, Hsien-Kai Kuo, Min-Hung Chen, Chia-Ming Cheng </h1>
</div>

<div id="abstract">
	<div>
		<div class="title-arxiv-pynet">
	       	<p><a target="_blank" href="https://arxiv.org/pdf/2211.06770"><img src="demo_microisp/microisp_title.png" width="100%"></a></p>
	    </div>
		<div class="title-info-pynet">
	    	<p> <span style="font-weight:bold">Abstract:</span> While neural networks-based photo processing solutions can provide a better image quality compared to the traditional ISP systems, their application to mobile devices is still very limited due to their very high computational complexity. In this paper, we present a novel MicroISP model designed specifically for edge devices, taking into account their computational and memory limitations. The proposed solution is capable of processing up to 32MP photos on recent smartphones using the standard mobile ML libraries and requiring less than 1 second to perform the inference, while for FullHD images it achieves real-time performance. The architecture of the model is flexible, allowing to adjust its complexity to devices of different computational power. To evaluate the performance of the model, we collected a novel Fujifilm UltraISP dataset consisting of thousands of paired photos captured with a normal mobile camera sensor and a professional 102MP medium-format FujiFilm GFX100 camera. The experiments demonstrated that, despite its compact size, the MicroISP model is able to provide comparable or better visual results than the traditional mobile ISP systems, while outperforming the previously proposed efficient deep learning based solutions. Finally, this model is also compatible with the latest mobile AI accelerators, achieving good runtime and low power consumption on smartphone NPUs and APUs.</p>
	        <p style="margin-top: 0.2vw;">
	        	<a target="_blank" href="https://arxiv.org/pdf/2211.06770"> arXiv: 2211.06770, 2022 </a>
	        	<a target="_blank" href="https://arxiv.org/pdf/2211.06263"><button class="follow-up"> View the Follow-Up Paper >> </button></a>
	        	<!--<a target="_blank" href="http://phancer.com/"><button class="follow-up" style="padding-left: 2.9vw; padding-right: 2.9vw; background-color: #f16b59;"> online demo </button></a>-->
	        </p>
		</div>
	</div>
</div>

<div id="demo">

	<h1 class="title">
		Sony IMX586 Sensor:&nbsp;&nbsp; <text class="highlight-color-blue">RAW Photos</text>&nbsp; vs. &nbsp;<text class="highlight-color">Reconstructed with MicroISP</text>
	</h1>
	
		<!-- Huawei P20 Images -->

	<figure class="cd-image-container">
		<img src="demo_microisp/visualized/1.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">RAW</span>
		
		<div class="cd-resize-img">
			<img src="demo_microisp/miscoisp/1.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">MicroISP</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_microisp/visualized/2.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">RAW</span>
		
		<div class="cd-resize-img">
			<img src="demo_microisp/miscoisp/2.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">MicroISP</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>


	<figure class="cd-image-container">
		<img src="demo_microisp/visualized/3.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">RAW</span>
		
		<div class="cd-resize-img">
			<img src="demo_microisp/miscoisp/3.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">MicroISP</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_microisp/visualized/4.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">RAW</span>
		
		<div class="cd-resize-img">
			<img src="demo_pynet/p20/processed/4.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">MicroISP</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	
</div>

<div id="dataset">

	<h1 class="title"> <text class="italic"> <text class="highlight-color">&#60;</text> Fujifilm UltraISP Dataset </text>&nbsp;<text class="highlight-color">&#62;</text> </h1>

	<p><img src="demo_microisp/Fujifilm_UltraISP.jpg" width="80%; margin-top: 1.2vw;"></p>

	<div>
		<div class="camsdd-info">
	    	<p>
	    	When dealing with an end-to-end learned smartphone ISP, the quality of the target images used for training the model plays a crucial. As our exploration revealed that none of the currently existing APS-C and full-frame cameras satisfy our quality requirements, we used the Fujifilm GFX100, a medium format 102 MP camera, for capturing the target high-quality photos. To collect the source RAW smartphone images, we chose a popular Sony IMX586 Quad Bayer camera sensor that can be found in tens of mid-range and high-end mobile devices released in the past 3 years. This sensor was mounted on the MediaTek Dimensity 820 development board, and was capturing both raw and processed (by its built-in ISP system) 12MP images. The cameras were capturing photos synchronously to ensure that the image content is identical. This setup was used for several weeks to collect over 6 thousand daytime image pairs at a wide variety of places with different illumination and weather conditions.
	    	</p>
			</br>	    	
	    	<p>
			As the collected RAW-RGB image pairs were not perfectly aligned, we had to perform local matching first. In order to achieve a precise pixel-wise alignment, we used the SOTA deep learning based dense matching algorithm to extract 256Ã—256 px patches from the original photos. This procedure resulted in over 99K pairs of crops that were divided into training (93.8K), validation (2.2K) and test (3.1K) sets and used for model training and evaluation.
	    	</p>
			<p>
			</br>
			<a href="https://codalab.lisn.upsaclay.fr/competitions/21561"><button class="camsdd-btn-download">Download&nbsp; Fujifilm&nbsp; UltraISP&nbsp; Dataset</button></a>
		</div>
	</div>
</div>


<div id="dataset">

	<h1 class="title"> <text class="italic"> <text class="highlight-color">&#60;</text> MicroISP Model </text>&nbsp;<text class="highlight-color">&#62;</text> </h1>

	<p><img src="demo_microisp/microisp_architecture.png" width="80%; margin-top: 1.2vw;"></p>

	<div>
		<div class="camsdd-info">
	    	<p>
	    	The model accepts the raw RGBG Bayer data coming directly from the camera sensor. The input is then grouped in 4 feature maps corresponding to each of the four RGBG color channels using the space-to-depth op. Next, this input is processed in parallel in 3 model branches corresponding to the R, G and B color channels and consisting of N residual building blocks. After applying the depth-to-space op at the end of each branch, their outputs are concatenated into the reconstructed RGB photo.
	    	</p>
	    	</br>
	    	<p>
			The proposed MicroISP model contains only layers supported by the Neural Networks API 1.2, and thus can run on any NNAPI-compliant AI accelerator (such as NPU, APU, DSP or GPU) available on mobile devices with Android 10 and above. The size of the MicroISP network is only 158 KB when exported for inference using the TFLite FP32 format. The model consumes around 90, 475 and 975MB of RAM when processing FullHD, 12MP and 32MP photos on mobile GPUs, respectively. Its GPU runtimes on various platforms for images of different resolutions are provided below:	
	    	</p>
			</br></br></br>
		</div>
	</div>
	
	<p><img src="demo_microisp/MicroISP_Runtime.png" width="80%; margin-top: 1.2vw;"></p>
	
</div>

<div id="code">
	<h1 class="title"> <text class="highlight-color-blue">&#60;</text> Code <text class="highlight-color-blue">&#62;</text> </h1>
	<p><text class="highlight-color-blue">TensorFlow</text> PyNET implementation and the entire training pipeline is available in our <a target="_blank" class="grey-link" href="https://github.com/aiff22/MicroISP">github repository</a></p>
	<br/>
</div>

<div id="cite">
		<h1 class="title"> Citation </h1>
		
		<p><text class="italic">Andrey Ignatov, Anastasia Sycheva </text> and <text class="italic">Radu Timofte, et al.</text></p>
		<p>"MicroISP: Processing 32MP Photos on Mobile Devices with Deep Learning",</p>
		<p>In <text class="italic">European Conference on Computer Vision (ECCV)</text>, 2022</p>
		<!--<br/>
		<br/>
		<br/>
		<p><text class="small-text">The work is supported by the ETH Zurich General Fund, Toyota via the project TRACE-Zurich, and an NVidia GPU grant.</text></p>-->

</div>

<div id="about">
	<div id="content">
		<!--<p>Contact: {ihnatova, nk, timofter, vanhoey}@vision.ee.ethz.ch</p>-->
		<p>ETH Zurich</p>
		<p>Switzerland, 2020-2025</p>
	</div>
</div>

<script src="js/jquery-2.1.1.js"></script>
<script src="js/jquery.mobile.custom.min.js"></script>
<script src="js/main.js"></script>
<script>
	function open_demo() {
		document.getElementById('demos').style.display="block";
		document.getElementById('demo-button').style.display="none";
	}
	function close_demo() {
		document.getElementById('demos').style.display="none";
		document.getElementById('demo-button').style.display="block";
	}
</script>
</body>

</html>
