<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title> MIDD Project </title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,700italic,400italic" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <script src="js/modernizr.js"></script>
    <meta name="viewport" content="width=device-width">

    <script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	
	  ga('create', 'UA-105303874-1', 'auto');
	  ga('send', 'pageview');
    </script>
</head>

<!--
<button id="demo-button" class="online-demo" onclick="open_demo();"><img src="assets/img/demo_button2.png"></button> 

<div id="demos" style="display:none">
	<a href="#" style="position: fixed; right: 2.2vmax; top: 6.3vw; color: white; z-index:9999; text-decoration: none; font-size: 1.2vmax;" onclick="close_demo()"> &#10006; </a>
	<iframe class="demo" src="http://quality-gpu.eastus.cloudapp.azure.com:8080" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" >
	<!--<iframe class="demo" src="http://127.0.0.1:5000/" name="targetframe" allowTransparency="true" scrolling="yes" frameborder="0" >
	</iframe>
</div>
-->

<body data-spy="scroll" data-offset="0" data-target="#navbar-main">

<!-- ==== MENU ==== -->

<nav>
	<ul class="left_bar">
		<a href="index.html"> <li2> DPED </li2></a>
		<a href="wespe.html"> <li2> WESPE </li2></a>
		<a href="pynet.html"> <li2> PyNET </li2></a>
		<a href="pynet-bokeh.html"> <li2> Bokeh </li2></a>
		<a href="microisp.html"> <li2> MicroISP </li2></a>
		<a href="camsdd.html"> <li2> CamSDD </li2></a>
		<a href="midd.html"> <li2 style="background-color: rgba(233,79,112, 0.85);"> MIDD </li2></a>
	</ul>
	<ul class="middle_bar">
		<a href="#title"> <li> PAPER </li></a>
		<a href="#demo"> <li> DEMO </li></a>
		<a href="#dataset"> <li> DATASET </li></a>
		<!--a href="#algo"> <li> ALGO </li></a-->
		<a href="#code"> <li> CODE </li></a>
	</ul>
	<ul class="right_bar">
		<a target="_blank" href="http://www.vision.ee.ethz.ch/en/" > <li> <img src="assets/img/eth_logo.png"> </li></a>
		<a href="#about"> <li> ABOUT </li></a>
	</ul>
</nav>

<div id="title">
<h1 class="title"> Real-World Mobile Image Denoising Dataset with Efficient Baselines </h1>

<table class="authors">
<tr>
	<td><a target="_blank" class = "link-invisible" href="https://ch.linkedin.com/in/roman-flepp">Roman Flepp</a></td>
	<td><a target="_blank" class = "link-invisible" href="https://ch.linkedin.com/in/andrey-ignatov">Andrey Ignatov</a></td>
	<td><a target="_blank" class = "link-invisible" href="https://www.informatik.uni-wuerzburg.de/computervision/">Radu Timofte</a></td>
	<td><a target="_blank" class = "link-invisible" href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a></td>
</tr>
<tr class="emails">
	<td>r.flepp@hotmail.com</td>
	<td>ihnatova@ethz.ch</td>
	<td>radu.timofte@uni-wuerzburg.de</td>
	<td>vangool@vision.ee.ethz.ch</td>
</tr>
</td>
</table>

<h1 class="institute"> CVPR 2024 Paper </h1>
</div>

<div id="abstract">
	<div>
		<div class="title-arxiv">
	       	<p><a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Flepp_Real-World_Mobile_Image_Denoising_Dataset_with_Efficient_Baselines_CVPR_2024_paper.pdf"><img src="demo_midd/midd_title.png" width="100%"></a></p>
	    </div>
		<div class="title-info">
	    	<p> <span style="font-weight:bold">Abstract:</span> The recently increased role of mobile photography has raised the standards of on-device photo processing tremendously. Despite the latest advancements in camera hardware, the mobile camera sensor area cannot be increased significantly due to physical constraints, leading to a pixel size of 0.6-2.0 Î¼m, which results in strong image noise even in moderate lighting conditions. In the era of deep learning, one can train a CNN model to perform robust image denoising. However, there is still a lack of a substantially diverse dataset for this task. To address this problem, we introduce a novel Mobile Image Denoising Dataset (MIDD) comprising over 400,000 noisy / noise-free image pairs captured under various conditions by 20 different mobile camera sensors. Additionally, we propose a new DPreview test set consisting of data from 294 different cameras for precise model evaluation. Furthermore, we present the efficient baseline model SplitterNet for the considered mobile image denoising task that achieves high numerical and visual results, while being able to process 8MP photos directly on smartphone GPUs in under one second. Thereby outperforming models with similar runtimes. This model is also compatible with recent mobile NPUs, demonstrating an even higher speed when deployed on them. The conducted experiments demonstrate high robustness of the proposed solution when applied to images from previously unseen sensors, showing its high generalizability.</p>
	        <p>
	        	<!--a target="_blank" href="https://arxiv.org/pdf/1704.02470.pdf"> arXiv: 1704.02470, 2017 </a-->
	        	<!--a target="_blank" href="wespe.html"><button class="follow-up"> view the follow-up paper >> </button></a-->
	        	<!--<a target="_blank" href="http://phancer.com/"><button class="follow-up" style="padding-left: 2.9vw; padding-right: 2.9vw; background-color: #f16b59;"> online demo </button></a>-->
	        </p>
		</div>
	</div>
</div>

<div id="demo">

	<h1 class="title">
		Sample Original vs. Denoised Images
	</h1>
	

	<figure class="cd-image-container">
		<img src="demo_midd/68_denoised.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/68_cropped.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_midd/227_denoised.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/227_cropped.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	
	
	
	<figure class="cd-image-container">
		<img src="demo_midd/664_denoised.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/664_cropped.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_midd/482_denoised.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/482_cropped.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_midd/983_denoised.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/983_cropped.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_midd/924_denoised.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/924_cropped.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	
	<h1 class="title">
		Comparison Against the Samsung S23 Ultra ISP Denoising Algorithm
	</h1>
	
	<figure class="cd-image-container">
		<img src="demo_midd/splitternet.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Our Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/noisy.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Original Image</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>

	<figure class="cd-image-container">
		<img src="demo_midd/splitternet.jpg" alt="Modified Image">
		<span class="cd-image-label" data-type="original">Our Denoised</span>
		
		<div class="cd-resize-img">
			<img src="demo_midd/samsung.jpg" alt="Original Image">
			<span class="cd-image-label" data-type="modified">Samsung Denoised</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	

</div>

<div id="dataset">

	<h1 class="title"> <text class="italic"> <text class="highlight-color">&#60;</text> Mobile Image Denoising Dataset </text>&nbsp; (MIDD) <text class="highlight-color">&#62;</text> </h1>

	<p><img src="demo_midd/MIDD.jpg" width="84%; margin-top: 1.2vw;"></p>

	<div>
		<div class="camsdd-info">
	    	<p>
	    	Our main goal was to develop a diverse and comprehensive real image denoising dataset consisting of photos captured using various mobile camera sensors. To achieve this, approximately 20,000 noisy images were collected for each of 20 different mobile camera sensors. The burst mode was used to capture 20 RAW Bayer images for each static scene with a custom Android application utilizing the Camera2 API, which allowed to bypass the phone's image signal processor (ISP) and prevent any internal image denoising. All photos were taken using a tripod and a remote control, ensuring no movement of the camera or its sensor. This approach yielded over 200K different noisy-to-ground-truth image pairs for each sensor, with 20 pairs per scene.
	    	</p>
			</br>	    	
	    	<p>
About 20% of the dataset was captured during the daytime, 50%-60% under less ideal conditions (like blue hour, dark indoor areas, artificial lighting), and roughly 20% during night-time or in very low light conditions. These varied conditions were crucial to encompass a broad range of real-world lighting situations as they have a strong impact on the noise distribution. Utilizing 20 different sensors, each with a unique noise pattern, was essential to introduce an even more diverse noise distribution. This process resulted in over 400,000 images in total (20 images per burst Ã 1000 scenes Ã 20 sensors).
	    	</p>
			<p>
			</br>
			<p><img src="demo_midd/MIDD_Sensors.jpg" width="100%; margin-top: 1.2vw;"></p>
			
			<a href="#"><button class="camsdd-btn-download">Download&nbsp; Mobile&nbsp; Image&nbsp; Denoising&nbsp; Dataset&nbsp; (MIDD) TBA</button></a>
		</div>
	</div>
</div>

<div id="dataset">

	<h1 class="title"> <text class="italic"> <text class="highlight-color">&#60;</text> DPreview Test Set </text>&nbsp;<text class="highlight-color">&#62;</text> </h1>

	<p><img src="demo_midd/dpreview.jpg" width="80%; margin-top: 1.2vw;"></p>

	<div>
		<div class="camsdd-info">
	    	<p>
	    	We also introduce an additional dataset collected by web-scraping the DPreview website. This site features an extensive camera comparison tool that showcases photos captured with various ISO levels for 294 different camera sensors. These range from low-end digital pocket cameras and phones to high-end cameras, including the Phase One IQ4 with its 150MP image sensor. The methodology for creating the images was consistent across all devices. A camera or phone was positioned centrally above the same scene, capturing RAW images starting from the lowest ISO level and ascending through the ISO range as far as each camera allowed. The chosen scene provides a rich array of colors, details, and intricate structures, making it an ideal environment for photography analysis.
	    	</p>
			</br>	    	
	    	<p>
			The alignment of the collected image data was performed using a sliding window approach. The images were then batched, with the lowest ISO image serving as the ground truth and the highest ISO levels as noisy samples. What sets this dataset apart is the unprecedented variety of image sensors it incorporates, surpassing in this aspect all previously used image denoising datasets by at least an order of magnitude. Consequently, this dataset provides an excellent resource for evaluating and testing image denoising models, as well as for assessing image denoising datasets themselves as will be discussed later.
	    	</p>
			<p>
			</br>
			<a href="#"><button class="camsdd-btn-download">Download&nbsp; DPreview&nbsp; Test&nbsp; Set&nbsp; TBA</button></a>
		</div>
	</div>
</div>

<div id="dataset">

	<h1 class="title"> <text class="italic"> <text class="highlight-color">&#60;</text> SplitterNet Model </text>&nbsp;<text class="highlight-color">&#62;</text> </h1>

	<p><img src="demo_midd/Splitternet.png" width="80%; margin-top: 1.2vw;"></p>

	<div>
		<div class="camsdd-info">
	    	<p>
	    		    	The SplitterNet architecture was developed taking into account various constraints imposed by mobile AI accelerators such as smartphone NPUs and GPUs. To reduce the model complexity, it performs splitting of tensors throughout the network to run the convolution operation on a smaller split tensor versus convolving the tensor without splitting. From a high-level view, the SplitterNet is a U-Net-based model with multiple paths, its overall architecture is shown above. After convolving the input, it is split along the channel axis. Runtime results of the SplitterNet model on various mobile GPUs and NPUs are provided below:
	    	</p>
			</br></br></br>
		</div>
	</div>
	
	<p><img src="demo_midd/Splitternet_runtime.png" width="80%; margin-top: 1.2vw;"></p>
	
</div>




<div id="code">
	<h1 class="title"> Code </h1>
	<p>TensorFlow implementation of the proposed models and the whole training pipeline is available in our <a target="_blank" class="grey-link" href="https://github.com/rflepp/SplitterNet-Efficient-Mobile-Denoising-Models-CVPR2024">github repo</a></p>
	<br/>
	<p>Pre-trained models can be downloaded separately <a target="_blank" class="grey-link" href="#">here</a></p>
	<br/>
	<p></p>
</div>

<div id="cite">
		<h1 class="title"> Citation </h1>
		
		<p><text class="italic">Roman Flepp, Andrey Ignatov, Radu Timofte </text> and <text class="italic">Luc Van Gool.</text></p>
		<p>"Real-World Mobile Image Denoising Dataset with Efficient Baselines",</p>
		<p>In <text class="italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</text>, 2024</p>
		<!--<br/>
		<br/>
		<br/>
		<p><text class="small-text">The work is supported by the ETH Zurich General Fund, Toyota via the project TRACE-Zurich, and an NVidia GPU grant.</text></p>-->

</div>

<div id="about">
	<div id="content">
		<!--<p>Contact: {ihnatova, nk, timofter, vanhoey}@vision.ee.ethz.ch</p>-->
		<p>ETH Zurich</p>
		<p>Switzerland, 2017-2025</p>
	</div>
</div>

<script src="js/jquery-2.1.1.js"></script>
<script src="js/jquery.mobile.custom.min.js"></script>
<script src="js/main.js"></script>
<script>
	function open_demo() {
		document.getElementById('demos').style.display="block";
		document.getElementById('demo-button').style.display="none";
	}
	function close_demo() {
		document.getElementById('demos').style.display="none";
		document.getElementById('demo-button').style.display="block";
	}
</script>
</body>

</html>
